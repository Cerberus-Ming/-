## 课程重点

![image-20240103113748399](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103113748399.png)

### 滤波

基本概念（了解，今年不考概念）

计算：给滤波核求滤波图像

设计滤波器（高斯噪声->平滑处理，均值滤波；滤波器的参数变化）

### 边缘检测

基本概念（了解）

计算：给定滤波核，计算边缘强度

> 注意边缘是一个矢量

Gaussian-Laplace检测子

Canny检测子

边缘检测性能评估

### 局部特征提取

#### Harris角点检测

很可能计算

#### SIFT算法

实现步骤

### 机器学习

#### 最近邻方法

概念

#### 线性分类器

基础的、每年都会考

要会算这个：<img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105154023176.png" alt="image-20240105154023176" style="zoom: 50%;" />

三个角度的理解

损失函数：多类 SVM 损失、交叉熵损失

> 考的话会给出公式

随机梯度速降：有哪些参数

### 神经网络

#### 全连接神经网络

结构

计算图前向、后向

神经网络的设计

#### 卷积神经网络

结构

会计算卷积、池化参数变化

经典的卷积神经网络

### 9-12章 实际应用

理解任务、概念、步骤

理解三个任务之间的区别和联系

也有可能考到

设计一个目标检测网络，网购结构，实现步骤等等

### 图像对齐和拼接

过程类似特征匹配

RANSAC算法

### 运动和光流

光流方程和最小化结果

参数化运动的概念

### 立体视觉

双目视觉系统几何模型

对极集合基本概念

## 一、概论

### 1、计算机视觉概念

计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。       

 作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取‘信息’的人工智能系统。

### 2、主要应用

3D建模、地图映射、计算摄影、手写字符识别、人脸检测、物体识别、生物视觉识别、目标识别、动画3D建模、AR/VR、自动驾驶、全景拼接、机器自主导航、工业视觉……

补充：

> 人类视觉特点
>
> - 信息筛选体制
>- 人类视觉盲区：忽略细节，视觉误区
> 
>问题提出：暑假计划
> 
>大卫 马尔（David Marr）：定义问题的三个层次
> 
>- 计算理论层：视觉计算的目标是什么？
> - 表达与算法层：为了完成计算理论，需要如何表达输入和输出、如何设计计算方法？
> - 硬件实现层：表达和算法的物理实现？
> 
>我们从图像中可以获得哪些信息：
> 
>- 3D信息：自动驾驶，从图片中建立罗马的三维场景
> - 语义信息：火车脱轨照片→事故

## 二、图像形成基本原理

### 1、针孔相机

![image-20240103114122329](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103114122329.png)

### 2、几何模型

（略）

## 二、卷积 图像滤波

### 1、数字图像表示

整数矩阵：

- 二进制图像（0，1）
- 灰度图像（0-255）
- 彩色图像（RGB三通道矢量函数，0-255）

### 2、图像基本操作

![image-20240103115004586](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103115004586.png)

### 3、卷积 图像去噪

#### 噪声

噪点：与周围图像差异较大的点（痘痘）

噪声类型：

![image-20240103121125690](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103121125690.png)

> 原来像素加上一个波动值，波动值满足正态（高斯）分布，且均值尽可能为0



#### 相关操作 卷积操作

**卷积与相关的比较：**

![image-20240103121445201](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103121445201.png)

> 在数学上，卷积和相关的定义非常相似，主要的区别在于对核的翻转。
>
> 在卷积运算中，核通常被翻转（或旋转180度）后再与输入信号进行运算。
>
> 而在相关运算中，核直接与输入信号进行运算。
>
> 注意：实际计算中，卷积核通常取对称的，因此翻转后可能与原来相同



**卷积核/滤波核（filter kernel）：**一个像素与其邻居的加权求和，卷积核记录的就是权值



**边缘（padding）处理：**

- 边缘卷积算不了，为了保证卷积后图像和原图大小相同，需要先将图像扩大
- 扩大方式：补0，最外边像素拉伸，镜像等等
- padding大小: 一般当窗口大小为(2k+1)*(2k+1)时padding k个单位



**卷积性质：**

- 线性（叠加、齐次）

- 平移不变

- 分配律

- 结合律

- **可分解**

  ![image-20231231171640484](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20231231171640484.png)

- **一个大高斯 = 多个小高斯连续操作（勾股定理关系）**

  

**卷积示例：**

- 中间1，周围0（脉冲滤波）：不变

- 中间行右边是1（移动滤波）：左移

  ![image-20240103122327267](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103122327267.png)

- 全1（均值滤波）：模糊

  ![image-20240103122403478](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103122403478.png)

- 锐化滤波：

  ![image-20240103122434279](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103122434279.png)

  > 锐化原理：均值平滑操作对边缘影响最大，原图-平滑图 = 边缘图
  >
  > 边界+原图 = 锐化
  >
  > 再由卷积的分配律结合律等性质可以得到上图公式
  >
  > **这个算子也叫做拉普拉斯算子，可以计算二阶导！**
  >
  > ![image-20231231173702897](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20231231173702897.png)
  >
  > ![img](https://bkimg.cdn.bcebos.com/pic/728da9773912b31ba6b10b618618367adbb4e19d?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U3Mg==,g_7,xp_5,yp_5/format,f_auto)



#### 高斯滤波

均值滤波的问题：出现原图不存在的条纹，振零现象。而希望离中心距离近的像素对输出影响大

**解决：用高斯函数产生卷积核**

![image-20231231170537658](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20231231170537658.png)

> 注意：高斯核是“对称”的，高斯核相关和卷积等价

**归一化：**使得卷积核权值和为1，图片存储范围不衰减不增加

**参数设置：**

$\sigma$和窗口大小两个参数，但实际上两者之间存在经验公式

> 一般卷积核窗宽 = $3\sigma+1$，以确保卷积有意义

$\sigma$越小越"集中"，滤波越不明显：

![image-20240103124434769](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103124434769.png)

![image-20240103124418386](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103124418386.png)



#### 中值滤波

高斯噪声可以使用高斯去噪

> 方差小，用$\sigma$小的高斯模板；方差大，用$\sigma$大的高斯模板。但是都会损失边缘信息

椒盐噪声、脉冲噪声可以使用**中值滤波**

> 注意：中值滤波不是线性的！适合消除某个非常跳脱的噪声点的影响。

![image-20240103130224144](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103130224144.png)

![image-20240103130547268](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103130547268.png)



### 4、模板匹配

**定义：**

- 模板是一副已知的小图像
- 模板匹配就是在一副大图像中搜寻目标
- 要找的目标同模板有相同的尺寸、方向和图像元素

![image-20240103233654406](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103233654406.png)



## 三、边缘检测

### 1、边缘及其分类

**边缘：信号突变的地方**

> 边的分类（一些边在某个特定的分析任务中可能成为噪声）：
>
> - 面的不连续
> - 形体的边
> - 阴影的边
> - 字符、花纹等等的边

### 2、边缘检测：导数

#### 导数概念

怎么找边？导数大的地方

实际：近似导数

![image-20240103234044128](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103234044128.png)

> 可以使用卷积[1,-1]计算

![image-20240103234122842](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103234122842.png)

#### 导数相关的组合检测子

- Prewitt：屏蔽单点噪声，防止把单点噪声检测成边

- Sobel：先平滑（高斯），再算导数

- Roberts：检测边的方向和1的方向垂直

  ![image-20231231215337414](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20231231215337414.png)

### 3、边缘检测：梯度

#### 梯度概念

![image-20240103234438629](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103234438629.png)

优势：边缘强度能综合两个方向的导数，以判定各个方向的边

#### 噪声影响

![image-20240103234852865](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103234852865.png)

![image-20240103234945928](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103234945928.png)

> 存在问题：由原图直接做求梯度的卷积，会因为噪点产生干扰波动
>
> 解决：先高斯平滑再求导数 
>
> 改进：两次连续卷积变为一次卷积，如下图

![image-20240101151950956](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240101151950956.png)

**这种高斯平滑+求偏导复合的卷积核，即为高斯偏导核**

### 4、高斯偏导核（高斯滤波核导数）

#### 基本特点

![image-20240103235801244](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103235801244.png)

- 边的方向核数值方向“垂直”
- 高斯平滑核求偏导得来

#### 高斯偏导核的参数

- 标准差、窗宽
- 经验公式：窗宽 = 3标准差+1
- 参数变化的影响：

![image-20240104000811057](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104000811057.png)

#### 高斯平滑核与高斯偏导核的区别

- 高斯平滑核是为了去噪和平滑，高斯偏导核是高斯核求偏导的复合
- 高斯平滑核是非负数，高斯偏导核可以有负数
- 高斯平滑核和为1，高斯偏导核和为0（保证平坦区域导数值为0）

#### Gaussian-Laplace检测子

laplace检测子可以求二阶导数

Gaussian-Laplace检测子就是先对图像进行高斯平滑，然后再应用拉普拉斯检测子

#### 常见的检测子

![image-20240104000601788](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104000601788.png)

![image-20240104000637528](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104000637528.png)

### 5、边缘检测步骤

- 平滑：抑制噪声
- 边缘增强：检测子滤波
- 边缘定位
  - 确定局部极值阈值
  - 细化：非最大化抑制

#### 非最大化抑制

目的：宽边变成细边

做法：沿梯度方向与（距离一个像素的）左右两个邻居比较，比两个邻居大则保留，否则去掉。如果点不在像素上，则需要别的点加权求和

问题：

- 断边现象：门限太高
- 解决办法：
  - 门限降低？不行，会引入噪声
  - 双门限的Canny算子

### 6、Canny检测子

**双门限**

- 高门限检测出鲁棒性比较强的边
- 低门限检测出比较全的边，其中包括噪音
- 低门限中非噪声的边会与高门限边有连接关系

Canny算子**（提取边缘非常有效的算法）**：

- 高斯滤波器，平滑 **考虑噪声**
- 计算梯度强度和梯度方向 **获取边信息**
- 非最大化抑制 **考虑粗边**
- 门限化  **考虑断边**

### 7、边缘检测：性能评估

#### 精准率与召回率

![image-20240104002421669](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104002421669.png)

#### PR曲线

- P以 Recall 为横轴，Precision 为纵轴。表示在不同阈值下的 Precision 和 Recall

- PR 曲线越接近右上角，表示算法的性能越好，同时具有较高的 Precision 和较高的 Recall

  <img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104002914627.png" alt="image-20240104002914627" style="zoom:50%;" />

## 四、多尺度空间

### 高斯金字塔

![image-20240104011512398](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104011512398.png)

- 高斯金字塔是一种图像金字塔，用于在不同尺度上表示图像
- 它是通过在原始图像上进行一系列高斯模糊和下采样操作得到的
- 构建步骤
  - 高斯平滑：卷积一个高斯核
  - 下采样：在模糊后的图像上进行下采样，即减少图像的分辨率。可以通过从模糊后的图像中选取间隔像素来实现。

## 五、局部特征

### 1、局部特征匹配

#### 引入：全景拼接任务

- 提取特征
- 匹配特征
- 使用特征点进行图片对齐

#### 好特征的要求

- 可重复性：两张图都可以检测到
- 显著性
- 易于计算
- 仅与局部相关：如果与全局相关会导致同一特征在不同图片中计算差异大
- **角点复合上述要求！**

#### 局部特征匹配的基本步骤

- 检测感兴趣特征点
- 提取特征点的不变描述

### 2、Harris角点

#### 角点概念

- 直观上：角
- 像素变化特征上：对于角点附近区域，图像梯度有两个或更多个主方向

#### 角点度量

- **窗口响应值E(u,v)**：框怎么挪，以及红绿框内容的差异，可以用于判断是否为角点

![image-20240104013111979](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013111979.png)

> w(x,y)：权重，用于控制特定位置点对E(u,v)的影响

- y泰勒展开：找到 E（u，v）和（u，v）之间的函数关系

![image-20240104013232806](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013232806.png)

![image-20240104013439216](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013439216.png)

> 到此为止，找到了（u，v）和E（u，v）的关系，相当于确定了函数类型，而M是函数系数。
>
> 那么（u，v）和E（u，v）的关系是什么关系呢？
>
> 直观理解：![image-20240102204251926](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240102204251926.png)横截面是圆、椭圆……

#### 矩阵M的含义

角点主方向与坐标轴对齐：

![image-20240104013704158](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013704158.png)

> IxIy = 0，因为一些点的Ix为0，一些点的Iy为0，还有的Ix和Iy都为0

角点主方向不与坐标轴对齐：

![image-20240104013825835](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013825835.png)

#### 角点响应函数

![image-20240104013944098](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104013944098.png)

#### Harris角点检测步骤

- 设定窗口，计算每个像素点的矩阵M
- 进而计算每个像素点的响应值R
- 找出具有较大响应值的点 (R > threshold)
- 确定R局部极值（非最大化抑制）

#### Harris角点检测特性

- 旋转不变性
- 不具有图像尺度缩放不变性

### *2、尺度不变区域

参考：https://blog.csdn.net/less_stronger/article/details/133834388

#### LoG检测子

- 高斯二阶导数（LoG模板）：具有尺度选择特性

- 归一化拉普拉斯算子：需要进行补偿$\sigma^2$，否则信号衰减

- 特征尺度r和拉普拉斯算子的$\sigma$有什么关系？

![image-20240103103646511](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103103646511.png)

**特征尺度大小和卷积核负范围相等时，即$\sigma = r / \sqrt{2}$**

#### 选择极点

输出：一系列圆，圈出特征点
![image-20240103105347944](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103105347944.png)

尺度不变特征则需要考虑尺度维的变化，需要在x,y,σ三维空间内寻找极值点，**点与上下两尺度和周围共26个点比较**

> 非尺度不变特征没有尺度信息，相当于固定尺度，只需在图像平面内寻找极值点，即与周围8个点比较）

- 选择尺度：三个$\sigma$一比，因为同一个圆心可以圈出多个圆（鼻尖和脸）
- 非最大化抑制：点和邻居比较，是邻居中最大的，才胜出

#### 优缺点和改进

优缺点：

- 优：检测完全
- 缺点：大模板运算慢

改进：

- Harris-Lalacian：只在Harris角点附近进行尺度检测
- SIFT：尺度不变特征

### 3、SIFT算法

Scale-Invariant Feature Transform：尺度不变特征变换

#### DOG检测子

![image-20240103200540060](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103200540060.png)

LoG和DoG模板长得非常相似，因此它们卷积的结果是相近的

DoG相比LoG可以实现计算提速：

![image-20240103201221044](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103201221044.png)

两个提速点：

- $k\sigma$的高斯卷积由$\sigma$高斯卷积结果再卷上$\sqrt{(k\sigma)^2-\sigma^2}$得到，利用了已有的结果，卷积核变小了，计算变快
- 大卷积 == 小图片

为了使得输出的尺度连续，需满足三个条件：
- $k = 2^{1/s}$
- 若**每层**要输出s个尺度，需要s+2个DoG层，需要s+2+1个高斯卷积核
- 下采样用倒数第三层，上图中即$k^2\sigma$

#### 局部特征描述

##### 特征点尺度

$r = \sqrt{2(k-1)}\sigma$

##### 特征点主方向

![image-20240104164938108](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104164938108.png)

- 计算图像中每个像素点的梯度
- 统计梯度方向的直方图（0-360度），直方图的峰值即为该区域的主方向
- 利用主方向可以使特征点对于旋转具有不变性

##### 特征描述子SIFT

![image-20240104164948412](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104164948412.png)

- 将块分为4x4 子块
- 16个单元分别统计每一单元像素梯度方向，即8个离散方向的直方图
- 最终描述子向量：4x4x8 = 128 维度

#### SIFT算法的步骤

- 计算高斯金字塔：运算分解、下采样
- 相减，得高斯差分金字塔
- 特征点提取：与8+9*2个点比较，找极值点
- 极值点筛选：阈值化、边缘响应检测等
- 确定特征点主方向：旋转不变性
- 特征点描述：特征描述子SIFT
- 进一步处理，以图像匹配为例
  - 特征点匹配
  - 后变换参数求解

> 图像匹配步骤：
>
> - 特征点提取
> - 特征点匹配
> - 匹配特征点筛选
> - 变换参数求解

#### *特征匹配

- 距离函数：SSD(f1, f2)，即平方差和
- 比值距离： SSD(f1, f2) / SSD(f1, f2’)
- 变换参数：根据一定数量的匹配特征点对，解方程即可

#### SIFT算法的特性

- 尺度不变性
- 旋转不变性
- 光照不变性
- 能适应一定视角的变化



## 六、机器学习

### 1、基本概念

#### 机器学习

产生动机：

- 计算机视觉任务具有复杂性
- 硬编码不可行，故考虑数据驱动方法

涵义：

- 构建模型，使计算机具备从数据中学习的能力，而不必显式地进行编程
- 机器学习的方法包括神经网络、决策树、支持向量机、聚类等

#### 神经网络

- 受生物神经系统启发的计算模型，通过模拟神经元之间的连接来实现学习
- 由神经元（节点）组成，这些神经元通过连接形成网络
  - 每个连接都有一个权重
  - 神经元接收输入、乘以权重，然后通过激活函数（引入非线性因素）产生输出

#### 过拟合和欠拟合

过拟合（Overfitting）和欠拟合（Underfitting）是机器学习领域中常用的两个概念

- 过拟合：模型过于复杂，学到了训练数据中的噪声和细节，背答案。训练集上好但测试集差，泛化能力差
- 欠拟合：模型通常过于简单，无法捕捉数据中的真实模式和复杂关系

### 2、最近邻分类

#### 基本思想

通过测量数据点之间的距离，将一个未标记的数据点分配给与其最近邻的已标记数据点相同的类别

#### 原理

距离：

![image-20240105180550227](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105180550227.png)

- L1 (曼哈顿距离)：两点之间在各个轴上的坐标差的绝对值之和
- L2 (欧氏距离)：两点之间的直线距离

临近点个数：

- 一个：最邻近
  - 离群点导致的波动问题
  - 改进：使用更多的临近点
- K个：K临近，K-Nearest Neighbors，KNN
  - 预测标签为K个最近邻样本标签的大多数
  - 类别之间可能存在空隙，解决：改变距离度量
  - K取7为佳

#### 超参数与验证集

超参数：在学习过程之前设置的参数，不是通过学习得到的

> K临近算法的K、学习率、batch-size和epoch都是超参数

数据集的划分：

![image-20240105181526277](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105181526277.png)

> 用训练集确定超参数可能导致过拟合，测试集不可以作为任何参数的依据，包括超参数。因此需要验证集

- 训练集：确定模型中非超参数的参数
- 验证集：确定超参数
- 测试集：评估模型繁华能力

#### 模型特点

优点：

- 简单
- 适用于小规模数据集

缺点：

- 测试复杂度高且缓慢
- 正确率不高，38.6%左右
- 无法给出数据的内在含义
- 不适合高维数据

### 3、线性分类器

#### 图像表示

一般分类器要求输入的是向量

一种向量表示方式：把矩阵拉成向量

#### 基本概念

一种**线性映射**，将输入的**图像特征映射为类别分数**

线性分类器的决策：得分最高的就是正确类

##### 代数角度理解：

![image-20240105184445143](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105184445143.png)

矩阵表示（更加紧凑）

![image-20210927173001044](https://img-blog.csdnimg.cn/img_convert/29338e1ea1cefc22ab5b522e9464bf4d.png#pic_center)

##### 可视化角度理解：

![在这里插入图片描述](https://img-blog.csdnimg.cn/b1a07881cd8e4bd18ad8940e3a0ea31b.png#pic_center)

- w权值信息，其实就是训练样本的统计信息，是每一类别的一个模板
- 如果输入的图片和某一类模板相似，则该类模板对应的分数更高

> 观察到两个马头，一个朝左，一个朝右，为什么呢？因为训练样本中就有的马头朝左，有的马头朝右

##### 几何角度理解：

决策边界：

![image-20240103224424316](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240103224424316.png)

- 分类器的本质就是将特征空间划分成若干个决策区域，落在同一区域内的点被判定为一个类
- 线性分类器的决策边界是一个线性方程（一条线）
  - w控制着线的方向，b控制着分界面的偏移
- 距离线越远得分越高

#### 损失函数

##### 基本概念

- 搭建了模型性能与模型参数之间的桥梁
- 指导模型参数优化

![image-20240104110219838](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104110219838.png)

> 重点：单个样本的损失怎么算

##### 多类支撑向量机损失

> 多类SVM损失

![image-20210927182203780](https://img-blog.csdnimg.cn/img_convert/6f84d6904635d184b3b0c562a5f8f216.png#pic_center)

<img src="https://img-blog.csdnimg.cn/img_convert/d9f0e5ddcd4ef8bb1de1293a2568e718.png#pic_center" alt="image-20210927182743861" style="zoom: 50%;" />

<img src="https://img-blog.csdnimg.cn/img_convert/4b312d309f7890ffcab4bca4af027582.png#pic_center" alt="image-20210927182900773" style="zoom:50%;" />

> 补充：w和b都很小时，L = 类别个数，这一性质可以用来检验编码是否正确

##### 交叉熵损失

> 多元Logistic回归

SoftMax操作：可以将属于某一类的分数，转化为概率

![image-20240104200837643](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104200837643.png)

- 取指数次方
- 归一化

交叉熵损失：

![在这里插入图片描述](https://img-blog.csdnimg.cn/ad4cdf9e417342a89fd2a07d890a8fa1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBASnNwZXIwNDIw,size_20,color_FFFFFF,t_70,g_se,x_16)

> 熵反映信息量，相对熵反映分布之间的不相似性
>
> 在分类任务条件下，p = [1,0,0]，H(p) = 0，交叉熵 = 相对熵

![在这里插入图片描述](https://img-blog.csdnimg.cn/3fa760ac63cf47029de3dba86975f192.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBASnNwZXIwNDIw,size_20,color_FFFFFF,t_70,g_se,x_16)

> 化简后，其实就是 **-log(正确类的概率) = log(1/正确类的概率)**

> 补充：实际中，存在交叉熵损失几乎不变，精度上升的情况，是因为分数接近但分数跨越了正确的”阈值“（0.33，0.34，0.33）

##### 正则项损失

![在这里插入图片描述](https://img-blog.csdnimg.cn/be768bf608344f70a9dd4f1df7d7feb3.png)

> 正则项让模型有偏好

<img src="https://img-blog.csdnimg.cn/d5433ccb8ac1455fac66282984dd295a.png#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

- L1正则项：权重·绝对值之和
- L2正则项：权重平方和
  - 喜欢小数值，惩罚大数值权值
  - 喜欢分散权值，鼓励分类器将所有维度特征用起来

#### 优化函数

##### 参数优化

- 利用损失函数输出值作为反馈信号
- 调整分类器参数
- 以提升分类器性能

##### 优化算法：梯度下降

![image-20240104145144339](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104145144339.png)

> 步长 = 学习率，神经网络调参中最重要的参数

计算梯度：

![image-20240104145358833](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104145358833.png)

> 计算量大且不精确

![image-20240104145523914](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104145523914.png)

> 算出导数表达式，然后带入数值计算
>
> 实际经常是解析求解，数值校验

##### 优化算法：随机梯度下降（SGD）

- 梯度下降算法的问题：当 N 很大时，所有样本点都求损失代价高

- 改进：随机梯度下降算法。使用一个很小的批计算损失

  > 批大小通常为 32 / 64 / 128

![image-20240104150114113](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104150114113.png)

超参数：

- epoch：一个通用参数， 一个 epoch 表示模型训练过程中，整个训练数据集被完整地前向传播和反向传播了一次
- batch-size == m（批大小）
- 一个epoch包含的迭代次数 = 总样本 / m
- 迭代次数（步数？）
- 数据采样方式
- 初始化权重



## 七、神经网络

### 全连接神经网络

#### 基本概念

> 线性分类器无法解决线性不可分问题

- 又称多层感知器（MLP）：级联多个（线性） 变换得到结果
- 全连接：神经元与前层所有神经元相连
- 激活函数：引入非线性操作，使多层神经网络不再是单纯线性的

#### 结构

![image-20240106010803153](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106010803153.png)

>max：激活函数

![image-20240106011513111](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106011513111.png)

>N层全连接神经网络：除输入层之外其他层的数量为N的网络

#### 激活函数

>  如果没有激活函数，全连接神经网络会退化成线性分类器

![image-20240104195018242](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104195018242.png)

- Sigmoid：将数据压缩到0-1之间
- tanh：将数据压缩到-1-1之间，且是对称的
- ReLU：求导简单
- Leaky ReLU：负数部分有一点点斜率

#### 网络结构参数

- 隐层神经元个数（宽度）
- 用几个隐层（深度）

![image-20240104195408749](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240104195408749.png)

> 太多不一定好，过拟合问题
>
> 深度深和宽度宽效果类似

#### 计算图与反向传播算法

![image-20240106011719619](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106011719619.png)

![image-20240106011804691](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106011804691.png)

计算度的颗粒度问题：

- 计算图的好处是把所有导数都展开了，导数计算容易，但是可能会太细碎
- 因此可以将计算图的一部分合并起来，手动计算导数，比如说上图sigmoid函数
- 因此计算图不是唯一的

### 卷积神经网络

#### 全连接神经网络的瓶颈

- 大图片时权值个数太大了，模型太复杂，一来是计算复杂，二来可能会导致过拟合
- 全连接神经网络仅适合 小图像 或者 表示成矢量的图像

#### 卷积神经网络的组成

![image-20240105001814395](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105001814395.png)

- 全连接层之前加上一系列卷积和池化层，用于提取图片特征，提炼信息

#### 感受野

感受野是神经元所"看到"的输入区域

感受野的计算：

- 单纯卷积，且卷积核大小不变时：
  ![image-20240106125729028](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106125729028.png)

- 更普遍的公式

  kn = 第n层卷积核大小    sn = 第n层步长      rn = 第n层感受野大小

  ![image-20240106130051357](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106130051357.png)

  ![image-20240106130229371](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106130229371.png)

#### 卷积相关计算

卷积神经网络的卷积核：

![image-20240106201920780](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106201920780.png)

- 和传统卷积核的区别：体状（具有深度）、包含偏置项b（偏置项是一个常数）
- 深度必须和图片深度匹配

更多的卷积：

- 原图可以卷积多个得到多个特征响应图
- 可以多次卷积，注意卷积的深度必须和上一层输出深度相同，而上一层输出深度由上一层卷积个数决定
- 下一层卷积深度 = 上一层卷积个数

![image-20240106202335714](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106202335714.png)

> 步长S：卷积核每次挪动几个位置  
>
> 填充P：边上补几排0
>
> 输出深度$C_{out}$ = 卷积核个数

![image-20240106200829486](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106200829486.png)

> 注意滤波核的大小实际上是 5 * 5 * 3
>
> <img src="https://api2.mubu.com/v3/document_image/2c0f4f1d-1db4-428b-aa94-f66fc223da9d-17206402.jpg" alt="image" style="zoom:67%;" />
>
> 学习参数规模 = 权重矩阵大小 + 偏置向量大小

#### 激活层

一般使用ReLU激活函数，不改变空间尺寸，导数计算方便

#### 池化
<img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105101350796.png" alt="image-20240105101350796" style="zoom: 80%;" />

> 作用：减少参数、增大感受野
>
> 池化操作对每一个深度通道单独进行，不影响深度

最大池化： 

- 区域内最大值代表区域
- 类似非最大化抑制！ 

 ![image-20240105101612363](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240105101612363.png)

> 丢失了75%的信息，但是类似非最大化抑制，保留了关键信息

## 八、三种实际应用

### 图像分类

#### 基本概念

- 根据图像的**语义信息**对不同**类别**图像进行**区分**

#### 基本步骤

- 提取特征
- 分类决策 

#### 经典网络

- AlexNet网络**规模较大**，同时**解决过拟合**，并且利用**多GPU加速**计算
  - AlexNet是一个相对较深的卷积神经网络
  - 引入了局部响应归一化层，对神经元的输出进行侧抑制，增强模型的泛化能力
  - 在全连接层引入了Dropout层，随机地在训练时将一些神经元的输出置为零，有助于防止过拟合。
- VGG通过增加**网络深度**，采用**小卷积核**，提高分类结果
  - 深度主要集中在卷积层，叠加多个卷积层和池化层
  - 小卷积核，增加网络的非线性，减少参数量，并提高模型表达能力
  - 最大池化（Max Pooling）层，降低数据的维度，减轻计算负担
- GoogLeNet引入了Inception模块、全局平均池化、辅助分类器，计算效率非常高
  - 引入的nception，融合不同尺度的特征信息，得到更好的特征表征
  - 全局平均池化代替全连接层大大减少了参数量
  - 添加两个辅助分类器帮助训练，避免梯度消失，也有一定的正则化效果，防止过拟合
- ResNet通过残差块，把浅层特征传递深层
  - 引入残差块，使网络可以学习残差（residual）映射，助于解决梯度消失和梯度爆炸问题
  - ResNet的残差结构允许其具有非常深的神经网络结构，避免了梯度问题



### 目标检测

#### 基本概念

- 找出图像中所有感兴趣的物体，确定它们的位置和大小

#### 经典网络

检测单一目标的一种网络结构：

![image-20240106114759487](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106114759487.png)

> 图像经过卷积、池化处理之后，分别进入两个全连接神经网络，两个网络分别负责分类和确定边框两个步骤
>
> 损失函数是类别损失和边框损失的加权求和

R-CNN网络结构和处理步骤：

![image-20240106114957845](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106114957845.png)



### 图像分割

#### 基本概念

- 区域分割
  - 将图像划分为若干个连通的区域
  - 如前景与后景分割开，猫的区域与背景分割

- 语义分割

  - 在普通分割的基础上，分类出每一块区域的语义（即这块区域是什么物体）

  - 把画面中的所有物体都指出它们各自的类别

- 实例分割
  - 在语义分割的基础上，给每个物体编号
  - 如这个是该画面中的CowA，那个是画面中的CowB

区域分割定义：

<img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106112745814.png" alt="image-20240106112745814" style="zoom: 67%;" />

#### 经典网络

- 区域分割

  - 阈值分割、区域生长、聚类、分裂归并

- 语义分割

  - 滑动窗

    ![image-20240106115202910](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106115202910.png)

    > 一个小窗口在图像上滑动，每次对窗口中的图像区域进行分类
    >
    > 问题：不高效，没有重复利用重叠块之间的共享特征

  - 全卷积神经网络（FCN）

    ![image-20240106115327531](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106115327531.png)

    > 去除全连接层，并将网络设计为多个卷积层级联，来一次实现所有像素预测
    >
    > 下采样层，减少分辨率，提高计算效率
    >
    > 上采样层，将网络输出的低分辨率特征图上采样至输入图像的分辨率
    >
    > 损失函数为每像素的交叉熵
    >
    > 如U-Net

- 实例分割

  - Mask R-CNN

  

## 九、图像对齐与拼接

### 双线性插值

解决图像放大的问题

原理：

![微信图片_20240107215624](C:\Users\钐二铭\Pictures\微信图片_20240107215624.png)

最终公式：

![image-20240107215804629](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107215804629.png)

> 注意如果是等比放大，（x，y）是通过等比放缩求得

例题：

![image](https://api2.mubu.com/v3/document_image/b1acd4ed-f075-4aa4-bd04-be5ff851d4aa-11806864.jpg)

### 2D坐标变换

![image-20240107224204726](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107224204726.png)

#### 仿射变换

> 线性变换和平移的组合，平行线仍然平行。包括平移、尺度、旋转、裁剪等

![image-20240107224304070](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107224304070.png)

<img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107224438874.png" alt="image-20240107224438874" style="zoom:67%;" />

#### 投影变换

<img src="C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107224606749.png" alt="image-20240107224606749" style="zoom:67%;" />

- 透视投影：平行线不平行
- 正交投影：平行线仍平行

![image-20240107224714387](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240107224714387.png)

- 需要多少个匹配特征点确定变换参数?

  需要三对非共线的匹配特征点

  > 因为仿射变换有六个参数，每个点提供两个方程（对应 x 和 y 坐标），所以至少需要三对匹配点来解这个方程组

### RANSAC

最小二乘法：

- 通过最小化误差的平方和寻找最佳拟合
- 问题：无法排除异常点，哪怕迭代效果也不好
- 改进：最小二乘法

RANSAC一次迭代的过程：

> 一次迭代产生一个模型，直到迭代次数达到阈值。最后在所有模型中取内点最多的

![image-20240108001507135](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240108001507135.png)

>内点：与模型的误差在允许范围内的点
>
>外点：与模型的误差在允许范围外的点

## 十、运动和光流

### 光流法

#### 基本概念

- 是一种运动估计算法
- 从时空图像亮度变化中直接恢复图像运动

#### 基本原理

![image](https://api2.mubu.com/v3/document_image/e551464a-b61e-41ec-9b99-7fa27e9a5917-11806864.jpg)

#### 块平移（L-K）算法

![image-20240106002222119](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240106002222119.png)

- 新的假设：小窗口中速度相等

### 参数化运动估计

#### 基本概念

- 已知运动的类型（如平移、旋转、仿射变换等），即已知函数求参数
- 通过调整一组参数，使得模型最好地拟合图像数据
- 这组参数就用来描述运动的具体特征

## 十一、立体视觉

- 单张图片回复三维场景不可能，因为二维图片丢失了深度信息
- 最少两张图片才能恢复三维场景

### 双目视觉系统的几何模型

> 可以看作对极几何的特例

![image-20240108003014192](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240108003014192.png)

### 对极几何

![image-20240108003137273](C:\Users\钐二铭\AppData\Roaming\Typora\typora-user-images\image-20240108003137273.png)

> O1、O2：相机中心

